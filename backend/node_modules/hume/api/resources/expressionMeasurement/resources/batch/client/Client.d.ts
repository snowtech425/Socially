/**
 * This file was auto-generated by Fern from our API Definition.
 */
/// <reference types="node" />
import * as environments from "../../../../../../environments";
import * as core from "../../../../../../core";
import * as Hume from "../../../../../index";
import * as stream from "stream";
import * as fs from "fs";
import { Blob } from "buffer";
export declare namespace Batch {
    interface Options {
        environment?: core.Supplier<environments.HumeEnvironment | string>;
        apiKey?: core.Supplier<string | undefined>;
        fetcher?: core.FetchFunction;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
    }
}
export declare class Batch {
    protected readonly _options: Batch.Options;
    constructor(_options?: Batch.Options);
    /**
     * Sort and filter jobs.
     *
     * @param {Hume.expressionMeasurement.batch.BatchListJobsRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.listJobs()
     */
    listJobs(request?: Hume.expressionMeasurement.batch.BatchListJobsRequest, requestOptions?: Batch.RequestOptions): Promise<Hume.expressionMeasurement.batch.UnionJob[]>;
    /**
     * Start a new measurement inference job.
     *
     * @param {Hume.expressionMeasurement.batch.InferenceBaseRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.startInferenceJob({
     *         urls: ["https://hume-tutorials.s3.amazonaws.com/faces.zip"],
     *         notify: true
     *     })
     */
    startInferenceJob(request: Hume.expressionMeasurement.batch.InferenceBaseRequest, requestOptions?: Batch.RequestOptions): Promise<Hume.expressionMeasurement.batch.JobId>;
    /**
     * Get the request details and state of a given job.
     *
     * @param {string} id - The unique identifier for the job.
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.getJobDetails("job_id")
     */
    getJobDetails(id: string, requestOptions?: Batch.RequestOptions): Promise<Hume.expressionMeasurement.batch.UnionJob>;
    /**
     * Get the JSON predictions of a completed inference job.
     *
     * @param {string} id - The unique identifier for the job.
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.getJobPredictions("job_id")
     */
    getJobPredictions(id: string, requestOptions?: Batch.RequestOptions): Promise<Hume.expressionMeasurement.batch.UnionPredictResult[]>;
    /**
     * Get the artifacts ZIP of a completed inference job.
     */
    getJobArtifacts(id: string, requestOptions?: Batch.RequestOptions): Promise<stream.Readable>;
    /**
     * Start a new batch inference job.
     *
     * @param {File[] | fs.ReadStream[] | Blob[]} file
     * @param {Hume.expressionMeasurement.batch.BatchStartInferenceJobFromLocalFileRequest} request
     * @param {Batch.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.expressionMeasurement.batch.startInferenceJobFromLocalFile([fs.createReadStream("/path/to/your/file")], {})
     */
    startInferenceJobFromLocalFile(file: File[] | fs.ReadStream[] | Blob[], request: Hume.expressionMeasurement.batch.BatchStartInferenceJobFromLocalFileRequest, requestOptions?: Batch.RequestOptions): Promise<Hume.expressionMeasurement.batch.JobId>;
    protected _getCustomAuthorizationHeaders(): Promise<{
        "X-Hume-Api-Key": string | undefined;
    }>;
}
